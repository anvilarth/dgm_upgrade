{"cells":[{"cell_type":"markdown","metadata":{"id":"mfuMscdgelAu"},"source":["## Task 1: Theory (3pt)\n","\n","In lecture 7 we proved the [ELBO surgery](http://approximateinference.org/accepted/HoffmanJohnson2016.pdf) theorem:\n","$$\n","    \\frac{1}{n} \\sum_{i=1}^n KL(q(\\mathbf{z} | \\mathbf{x}_i) || p(\\mathbf{z})) = KL(q(\\mathbf{z}) || p(\\mathbf{z})) + \\mathbb{I}_{q} [\\mathbf{x}, \\mathbf{z}],\n","$$\n","where the first term is $KL(q(\\mathbf{z}) || p(\\mathbf{z}))$ includes the aggregated posterior distribution $q(\\mathbf{z})$ and the prior distribution $p(\\mathbf{z})$. Our goal now is to deal with the second term. At the lecture, the second term was equal to:\n","\n","$$\n","    \\mathbb{I}_{q} [\\mathbf{x}, \\mathbf{z}] = \\frac{1}{n}\\sum_{i=1}^n KL(q(\\mathbf{z} | \\mathbf{x}_i) || q (\\mathbf{z})).\n","$$\n","In fact, this is a mutual information between $\\mathbf{x}$ and $\\mathbf{z}$ on the empirical distribution of data and the distribution of $q(\\mathbf{z} | \\mathbf{x})$. Let treat the index of the sample $i$ as a random variable.\n","$$\n","    q(i, \\mathbf{z}) = q(i) q(\\mathbf{z} | i); \\quad p(i, \\mathbf{z}) = p(i) p(\\mathbf{z}); \\quad \n","    q(i) = p(i) = \\frac{1}{n}.\n","$$\n","$$\n","    \\quad q(\\mathbf{z} | i) = q(\\mathbf{z} | \\mathbf{x}_i) \\quad q(\\mathbf{z}) = \\sum_{i=1}^n q(i, \\mathbf{z}) = \\frac{1}{n} \\sum_{i=1}^n q(\\mathbf{z} | \\mathbf{x}_i);  \n","$$\n","Mutual information is a measure of independence between two random variables.\n","$$\n","\t\\mathbb{I}_{q} [\\mathbf{x}, \\mathbf{z}] = \\mathbb{E}_{q(i, \\mathbf{z})} \\log \\frac{q(i, \\mathbf{z})}{q(i)q(\\mathbf{z})}.\n","$$\n","Prove that 2 expressions for mutual information are equal to each other."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### ADD INSTALLING PIP PACKAGE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ieenT6NCp_OK"},"outputs":[],"source":["import os\n","import pickle\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import make_moons\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","from torch.distributions.uniform import Uniform\n","from torch.distributions.normal import Normal\n","\n","USE_CUDA = torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from dgm_utils import train_model, plot_training_curves\n","from dgm_utils import visualize_images, load_pickle\n","from dgm_utils import grid_preprocessing, show_samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQeQeajnkCFV"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"_HLQR8FikQd_"},"source":["# Task 2: VAE with Autoregressive flow-based prior on CIFAR10 (5pt)\n","\n","In this task you will fit the VAE model with [flow-based prior](https://arxiv.org/abs/1611.02731) to the CIFAR10 dataset (download it [here](https://drive.google.com/file/d/16j3nrJV821VOkkuRz7aYam8TyIXLnNme/view?usp=sharing)).  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dTW5lhwv-J9w"},"outputs":[],"source":["# change the path to the generated data\n","train_data, test_data = load_pickle('/content/cifar10.pkl', flatten=False)\n","train_data = torch.tensor(train_data).float() / 255\n","test_data = torch.tensor(test_data).float() / 255\n","\n","visualize_images(train_data, 'CIFAR10 samples')"]},{"cell_type":"markdown","metadata":{"id":"EMNE7poKkqio"},"source":["The model consists of:\n","* convolutional encoder (variational posterior destrituion $q(\\mathbf{z} | \\mathbf{x})$)\n","* convolutional decoder $p(\\mathbf{x} | \\mathbf{z})$\n","* autoregressive prior\n","\n","We will use MADE model for autoregressive prior. MADE Autoregressive frow (mapping from $\\mathbf{z}\\rightarrow \\boldsymbol{\\epsilon}$) should output location $\\mu(\\mathbf{z})$ and scale parameters $\\sigma(\\mathbf{z})$. The mapping from $\\mathbf{z}$ to $\\boldsymbol{\\epsilon}$ has the form:\n","$$\n","    \\boldsymbol{\\epsilon} = \\mathbf{z} * \\sigma(\\mathbf{z}) + \\mu(\\mathbf{z}).\n","$$\n","\n","The ELBO objective in this task is:\n","$$\n","    -E_{\\mathbf{z}\\sim q(\\mathbf{z}|\\mathbf{x})}[\\log{p(x|\\mathbf{z})}] + E_{z\\sim q(\\mathbf{z}|\\mathbf{x})}[\\log{q(\\mathbf{z}|\\mathbf{x})} - \\log{p(\\mathbf{z})}]\n","$$\n","where \n","$$\n","    \\log{p(\\mathbf{z})} = \\log{p(\\boldsymbol{\\epsilon})} + \\log{\\det\\left|\\frac{d\\boldsymbol{\\epsilon}}{d\\mathbf{z}}\\right|}.\n","$$\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ItwpO0MVqWv9"},"outputs":[],"source":["def get_normal_KL(mean_1, log_std_1, mean_2=None, log_std_2=None):\n","    \"\"\"\n","        This function should return the value of KL(p1 || p2),\n","        where p1 = Normal(mean_1, exp(log_std_1)), p2 = Normal(mean_2, exp(log_std_2) ** 2).\n","        If mean_2 and log_std_2 are None values, we will use standart normal distribution.\n","        Note that we consider the case of diagonal covariance matrix.\n","    \"\"\"\n","    if mean_2 is None:\n","        mean_2 = torch.zeros_like(mean_1)\n","    if log_std_2 is None:\n","        log_std_2 = torch.zeros_like(log_std_1)\n","    # ====\n","    # your code\n","    \n","    # ====\n","\n","\n","def test_KL():\n","    assert np.isclose(get_normal_KL(torch.tensor(2), torch.tensor(3), torch.tensor(0), torch.tensor(0)).numpy(), 200.2144, rtol=1e-3)\n","    assert np.isclose(get_normal_KL(torch.tensor(2), torch.tensor(3), torch.tensor(4), torch.tensor(5)).numpy(), 1.50925, rtol=1e-3)\n","    assert np.allclose(get_normal_KL(torch.tensor((10, 10)), torch.tensor((2, 4)), torch.tensor((3, 5))).numpy(), [49.2990, 1498.479], rtol=1e-3)\n","\n","test_KL()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W3AxLZam9cb-"},"outputs":[],"source":["class ConvEncoder(nn.Module):\n","    # do not change this class\n","    def __init__(self, input_shape, n_latent):\n","        super().__init__()\n","        self.input_shape = input_shape\n","        self.n_latent = n_latent\n","        self.convs = nn.Sequential(\n","            nn.Conv2d(input_shape[0], 32, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n","        )\n","        conv_out_dim = input_shape[1] // 8 * input_shape[2] // 8 * 256\n","        self.fc = nn.Linear(conv_out_dim, 2 * n_latent)\n","\n","    def forward(self, x):\n","        out = self.convs(x)\n","        out = out.view(out.shape[0], -1)\n","        mu, log_std = self.fc(out).chunk(2, dim=1)\n","        return mu, log_std\n","        \n","\n","class ConvDecoder(nn.Module):\n","    # do not change this class\n","    def __init__(self, n_latent, output_shape):\n","        super().__init__()\n","        self.n_latent = n_latent\n","        self.output_shape = output_shape\n","\n","        self.base_size = (128, output_shape[1] // 8, output_shape[2] // 8)\n","        self.fc = nn.Linear(n_latent, np.prod(self.base_size))\n","        self.deconvs = nn.Sequential(\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(128, 128, 4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(32, output_shape[0], 3, padding=1),\n","        )\n","\n","    def forward(self, z):\n","        out = self.fc(z)\n","        out = out.view(out.shape[0], *self.base_size)\n","        return self.deconvs(out)\n","\n","\n","class MaskedLinear(nn.Linear):\n","    # do not change this class\n","    def __init__(self, in_features, out_features, bias=True):\n","        super().__init__(in_features, out_features, bias)\n","        self.register_buffer('mask', torch.ones(out_features, in_features))\n","\n","    def set_mask(self, mask):\n","        self.mask.data.copy_(torch.from_numpy(mask.astype(np.uint8).T))\n","\n","    def forward(self, input):\n","        return F.linear(input, self.mask * self.weight, self.bias)\n","\n","\n","class MADE(nn.Module):\n","    # do not change this class\n","    def __init__(self, input_shape, d, hidden_size=[512, 512]):\n","        super().__init__()\n","        self.input_shape = input_shape\n","        self.nin = np.prod(input_shape)\n","        self.nout = self.nin * d\n","        self.d = d\n","        self.hidden_sizes = hidden_size\n","        self.ordering = np.arange(self.nin)\n","\n","        self.net = []\n","        hs = [self.nin] + self.hidden_sizes + [self.nout]\n","        for h0, h1 in zip(hs, hs[1:]):\n","            self.net.extend([\n","                MaskedLinear(h0, h1),\n","                nn.ReLU(),\n","            ])\n","        self.net.pop()\n","        self.net = nn.ModuleList(self.net)\n","\n","        self.m = {}\n","        self.create_mask()\n","\n","    def create_mask(self):\n","        L = len(self.hidden_sizes)\n","\n","        self.m[-1] = self.ordering\n","        for l in range(L):\n","            self.m[l] = np.random.randint(self.m[l - 1].min(),\n","                                          self.nin - 1, size=self.hidden_sizes[l])\n","\n","        masks = [self.m[l - 1][:, None] <= self.m[l][None, :] for l in range(L)]\n","        masks.append(self.m[L - 1][:, None] < self.m[-1][None, :])\n","\n","        masks[-1] = np.repeat(masks[-1], self.d, axis=1)\n","\n","        layers = [l for l in self.net.modules() if isinstance(l, MaskedLinear)]\n","        for l, m in zip(layers, masks):\n","            l.set_mask(m)\n","\n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","        out = x.view(batch_size, self.nin)\n","        for layer in self.net:\n","            out = layer(out)\n","        out = out.view(batch_size, self.nin, self.d)\n","        return out\n","\n","\n","class ARFPriorVAE(nn.Module):\n","    def __init__(self, input_shape, n_latent):\n","        super().__init__()\n","        assert len(input_shape) == 3\n","        self.input_shape = input_shape\n","        self.n_latent = n_latent\n","\n","        # ====\n","        # your code\n","        # define made model, encoder and decoder\n","        # ====\n","    \n","    def prior(self, n, use_cuda=True):\n","        # ====\n","        # your code\n","        # return n samples from prior distribution (we use standart normal for prior)\n","        \n","        # ====\n","        z = ...\n","        if use_cuda:\n","            z = z.cuda()\n","        return z\n","\n","    def loss(self, x):\n","        # ====\n","        # your code\n","        # 1) apply encoder to x to get variational distribution parameters\n","        # 2) sample z from variational distribution\n","        # 3) apply decoder to get reconstruction\n","        \n","        \n","        # ====\n","\n","        # ====\n","        # your code\n","        # 1) compute reconstruction loss \n","        # in this case we could use mse loss \n","        # (we will get beta-VAE model since the contributions of reconstruction loss and KL term become dishonest) \n","        # 2) compute encoder log prob (it is a log of normal distribution on z)\n","        # 3) apply MADE model to z to get mu and log_std\n","\n","        # ====\n","\n","        # this trick is just for model stability (do not touch it)\n","        log_std = torch.tanh(log_std)\n","\n","        # ====\n","        # your code\n","        # 1) scale z to sigma and shift to mu get epsilon\n","        # 2) compute prior log prob (log of standart normal)\n","        # 3) kl loss is difference between encoder log prob and prior log prob\n","\n","        # ====\n","        return {\n","            'total_loss': recon_loss + kl_loss,\n","            'recon_loss': recon_loss,\n","            'kl_loss': kl_loss\n","        }\n","\n","    def sample(self, n=0, noise=None, determenistic=False, use_cuda=True):\n","        if noise is not None:\n","            z = noise\n","            n = len(noise)\n","        else:\n","            z = self.prior(n, use_cuda)\n","            \n","        if use_cuda:\n","            z = z.cuda()\n","                \n","        # investigate how to sample from autoregressive model (do not change this part)\n","        for i in range(self.n_latent):\n","            mu, log_std = self.made(z)[:, i].chunk(2, dim=-1)\n","            log_std = torch.tanh(log_std)\n","            mu, log_std = mu.squeeze(-1), log_std.squeeze(-1)\n","            z[:, i] = (z[:, i] - mu) * torch.exp(-log_std)\n","        return torch.clamp(self.decoder(z), 0, 1).cpu()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JcMArVCA9ckD"},"outputs":[],"source":["wandb.init(project=\"your project name\")\n","# ====\n","# your code\n","# choose these parameters\n","BATCH_SIZE =   # any adequate value\n","EPOCHS =       # < 10\n","LR =           # < 1e-3\n","# ====\n","\n","train_data, test_data = load_pickle(os.path.join('drive', 'MyDrive', 'DGM', 'homework_supplementary', 'cifar10.pkl'))\n","model = ARFPriorVAE((3, 32, 32), 16)\n","\n","train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE)\n","train_losses, test_losses = train_model(model, train_loader, test_loader, use_cuda=USE_CUDA, \n","                                        epochs=EPOCHS, use_tqdm=True, lr=LR, preprocess=grid_preprocessing)\n","\n","plot_training_curves(train_losses, test_losses)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"beJCpjz0edsW"},"outputs":[],"source":["with torch.no_grad():\n","    samples = model.sample(100)\n","\n","x = next(iter(test_loader))[:50]\n","if USE_CUDA:\n","    x = x.cuda()\n","\n","with torch.no_grad():\n","    z, _ = model.encoder(x)\n","    x_recon = torch.clamp(model.decoder(z), 0, 1)\n","reconstructions = torch.stack((x, x_recon), dim=1).view(-1, 3, 32, 32)\n","reconstructions = reconstructions.cpu()\n","\n","x = next(iter(test_loader))[:20]\n","if USE_CUDA:\n","    x = x.cuda()\n","\n","with torch.no_grad():\n","    z, _ = model.encoder(x)\n","    z1, z2 = z.chunk(2, dim=0)\n","    interps = [model.decoder(z1 * (1 - alpha) + z2 * alpha) for alpha in torch.linspace(0, 1, 10)]\n","    interps = torch.stack(interps, dim=1).view(-1, 3, 32, 32)\n","    interps = torch.clamp(interps, 0, 1)\n","interps = interps.cpu()\n","\n","for key, value in test_losses.items():\n","    print('{}: {:.4f}'.format(key, value[-1]))\n","\n","show_samples(reconstructions, 'CIFAR10 reconstructions')\n","show_samples(samples, 'CIFAR10 samples')\n","show_samples(interps, 'CIFAR10 interpolation')\n"]},{"cell_type":"markdown","metadata":{"id":"qZZ-ef7XkQiT"},"source":["# Task 3: VAE with Autoregressive decoder on MNIST (5pt)\n","\n","In this task you will fit the VAE model with [autoregressive decoder](https://arxiv.org/abs/1611.05013) to the MNIST dataset (download it [here](https://drive.google.com/file/d/1Ms-RBybrueI3_w2CRj7lM9mYjfvFRL6w/view?usp=sharing))."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d7SDW4JHgKFr"},"outputs":[],"source":["# change the path to the file\n","train_data, test_data = load_pickle(\n","    os.path.join('drive', 'My Drive', 'DGM', 'homework_supplementary', 'mnist.pkl'),\n","    flatten=False\n",")\n","\n","train_data = torch.tensor(train_data).float() / 255\n","test_data = torch.tensor(test_data).float() / 255\n","\n","visualize_images(train_data.reshape(-1, 1, 28, 28), 'MNIST samples')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iazovzdJpc2Q"},"outputs":[],"source":["class MaskedConv2d(nn.Conv2d):\n","    def __init__(self, mask_type, in_channels, out_channels, kernel_size=5, padding=0, conditional_size=None):\n","        assert mask_type in ['A', 'B']\n","        super().__init__(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding)\n","        self.register_buffer('mask', torch.zeros_like(self.weight))\n","        self.create_mask(mask_type)\n","\n","        if conditional_size is not None:\n","            self.cond_op = nn.Linear(conditional_size, self.out_channels)\n","\n","    def forward(self, input, cond=None):\n","        # ====\n","        # your code\n","        # apply masked convolution and get \"out\" variable\n","\n","        # ====\n","\n","        if cond is not None:\n","            cond = self.cond_op(cond)\n","            out = out + cond.view(cond.shape[0], self.out_channels, 1, 1)\n","        return out\n","\n","    def create_mask(self, mask_type):\n","        # ====\n","        # your code\n","        # do not forget about mask_type\n","        \n","        # ====\n","\n","\n","def test_masked_conv2d():\n","    layer = MaskedConv2d('A', 2, 2)\n","    assert np.allclose(layer.mask[:, :, 2, 2].numpy(), np.zeros((2, 2)))\n","\n","    layer = MaskedConv2d('B', 2, 2)\n","    assert np.allclose(layer.mask[:, :, 2, 2].numpy(), np.ones((2, 2)))\n","\n","\n","test_masked_conv2d()"]},{"cell_type":"markdown","metadata":{"id":"Pb0FcBizpYLO"},"source":["[Layer Normalization](https://arxiv.org/abs/1607.06450) helps to stabilize training process."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o0IbeNTGpWIx"},"outputs":[],"source":["class LayerNorm(nn.LayerNorm):\n","    def __init__(self, n_filters):\n","        super().__init__(n_filters)\n","\n","    def forward(self, x):\n","        x = x.permute(0, 2, 3, 1).contiguous()\n","        x = super().forward(x)\n","        return x.permute(0, 3, 1, 2).contiguous()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4J1G9LDCerC"},"outputs":[],"source":["class PixelCNN(nn.Module):\n","    def __init__(\n","        self, \n","        input_shape, \n","        n_filters=256, \n","        kernel_size=3, \n","        n_layers=7,\n","        use_layer_norm=True,\n","        conditional_size=None\n","    ):\n","        super().__init__()\n","        self.input_shape = input_shape\n","        \n","        # ====\n","        # your code\n","        # apply the sequence of MaskedConv2d -> LayerNorm -> ReLU\n","        # note that the first conv layer should be of type 'A'\n","        # the last layer should be MaskedConv2d\n","        # define self.net as list of layers\n","        # NOTE 1: padding must be (kernel_size - 1) // 2\n","        # NOTE 2: final output_dim in MaskedConv2d must be 2\n","\n","        # ====\n","\n","    def forward(self, x, cond=None):\n","        out = (x.float() - 0.5) * 2\n","        for layer in self.net:\n","            if isinstance(layer, MaskedConv2d):\n","                out = layer(out, cond=cond)\n","            else:\n","                out = layer(out)\n","        return out.view(x.shape[0], 2, 1, *self.input_shape)\n","\n","    def loss(self, x, cond=None):\n","        # ====\n","        # your code\n","        # NOTE: for example F.cross_entropy\n","        \n","        # ====\n","\n","    def sample(self, n, cond=None, use_cuda=True):\n","        # read carefully the sampling process\n","        samples = torch.zeros(n, 1, *self.input_shape)\n","        if use_cuda:\n","            samples = samples.cuda()\n","        \n","        with torch.no_grad():\n","            for r in range(self.input_shape[0]):\n","                for c in range(self.input_shape[1]):\n","                    logits = self(samples)[:, :, :, r, c]\n","                    probs = F.softmax(logits, dim=1).squeeze(-1)\n","                    samples[:, 0, r, c] = torch.multinomial(probs, num_samples=1).squeeze(-1)\n","        return samples.cpu().numpy()\n","\n","\n","class ConvEncoder(nn.Module):\n","    def __init__(self, input_shape, latent_dim):\n","        super().__init__()\n","        self.input_shape = input_shape\n","        self.latent_dim = latent_dim\n","        self.convs = nn.Sequential(\n","            nn.Conv2d(1, 32, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(32, 32, 3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n","        )\n","        conv_out_dim = input_shape[0] // 4 * input_shape[1] // 4 * 64\n","        self.fc = nn.Linear(conv_out_dim, 2 * latent_dim)\n","\n","    def forward(self, x):\n","        x = (x.float() - 0.5) * 2\n","        out = self.convs(x)\n","        out = out.view(out.shape[0], -1)\n","        mu, log_std = self.fc(out).chunk(2, dim=1)\n","        return mu, log_std\n","\n","\n","class ARDecoderVAE(nn.Module):\n","    def __init__(self, input_shape, n_latent, free_bits=None):\n","        super().__init__()\n","        assert len(input_shape) == 2\n","\n","        self.input_shape = input_shape\n","        self.n_latent = n_latent\n","        self.free_bits = free_bits\n","        self.encoder = ConvEncoder(input_shape, n_latent)\n","        self.decoder = PixelCNN(\n","            input_shape, \n","            n_filters=32, \n","            n_layers=3,\n","            kernel_size=5, \n","            conditional_size=n_latent\n","        )\n","\n","    def prior(self, n, use_cuda):\n","        # ====\n","        # your code\n","        # return n samples from prior distribution (we use standart normal for prior)\n","        \n","        # ====\n","        z = ...\n","        if use_cuda:\n","            z = z.cuda()\n","        return z\n","\n","    def loss(self, x):\n","        # ====\n","        # your code\n","        # 1) apply encoder\n","        # 2) apply reparametrization trick\n","        # 3) get decoder loss (reconstruction loss)\n","        # 4) get kl loss using get_normal_KL\n","        # 5) apply free_bits\n","        \n","        # ====\n","\n","        return {\n","            'total_loss': recon_loss + kl_loss, \n","            'recon_loss': recon_loss,\n","            'kl_loss': kl_loss\n","        }\n","\n","    def sample(self, n, use_cuda=True):\n","        z = self.prior(n, use_cuda)\n","        samples = self.decoder.sample(n, cond=z)\n","        return samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i4IgkdDuCetl"},"outputs":[],"source":["wandb.init(project=\"your project name\")\n","# ====\n","# your code\n","# choose these parameters\n","BATCH_SIZE =   # any adequate value\n","EPOCHS =       # < 10 \n","LR =           # < 1e-3\n","FREE_BITS =    # < 1\n","# ====\n","\n","model = ARDecoderVAE(input_shape=(28, 28), free_bits=FREE_BITS, n_latent=16)\n","train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE)\n","\n","train_losses, test_losses = train_model(model, train_loader, test_loader, epochs=EPOCHS, \n","                                        use_cuda=USE_CUDA, use_tqdm=True, lr=LR, preprocess=grid_preprocessing)\n","\n","plot_training_curves(train_losses, test_losses)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E_X3IGjWCew0"},"outputs":[],"source":["with torch.no_grad():\n","    samples = model.sample(100)\n","\n","x = next(iter(test_loader))[:50]\n","if USE_CUDA:\n","    x = x.cuda()\n","\n","with torch.no_grad():\n","    z, _ = model.encoder(x)\n","    x_recon = torch.clamp(model.decoder(z), 0, 1)\n","reconstructions = torch.stack((x, x_recon), dim=1).view(-1, 3, 32, 32)\n","reconstructions = reconstructions.cpu()\n","\n","\n","x = next(iter(test_loader))[:20]\n","if USE_CUDA:\n","    x = x.cuda()\n","\n","with torch.no_grad():\n","    z, _ = model.encoder(x)\n","    z1, z2 = z.chunk(2, dim=0)\n","    interps = [model.decoder(z1 * (1 - alpha) + z2 * alpha) for alpha in torch.linspace(0, 1, 10)]\n","    interps = torch.stack(interps, dim=1).view(-1, 3, 32, 32)\n","    interps = torch.clamp(interps, 0, 1)\n","interps = interps.cpu()\n","\n","show_samples(reconstructions, 'MNIST reconstructions')\n","show_samples(samples, 'MNIST samples')\n","show_samples(interps, 'MNIST interpolation')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"hw4.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
